{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afcd202-e82a-46e8-b757-84edd141d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4bd895-841d-43b8-a8cb-89df8d7421d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 이미지 크기를 64x64로 조정\n",
    "    transforms.ToTensor(),         # 이미지를 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e3f52e-929c-4bf0-a222-79c79d39e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageComparisonModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageComparisonModel, self).__init__()\n",
    "        \n",
    "        # Stream 1 for the first image modality\n",
    "        self.stream1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Stream 2 for the second image modality\n",
    "        self.stream2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Fusion and decision mechanism\n",
    "        self.comparison = nn.Sequential(\n",
    "            nn.Linear(16*16*256*2, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),  # Binary classification\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.stream1(x1)\n",
    "        x2 = self.stream2(x2)\n",
    "        \n",
    "        # Flatten the features from both streams\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        \n",
    "        # Concatenate the features\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        \n",
    "        # Pass through the comparison mechanism\n",
    "        x = self.comparison(x)\n",
    "        # Apply softmax to get probabilities\n",
    "        # x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4757daec-d522-4405-89f7-01c408eea9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 .pth 파일의 경로\n",
    "saved_model_path = \"Check_Model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0cef99-6721-41fb-8eb0-920925cb9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 클래스의 인스턴스 생성\n",
    "loaded_model = ImageComparisonModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d303eb2e-41f0-4c0e-b4f4-6b5b1535594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델의 가중치 불러오기\n",
    "loaded_model.load_state_dict(torch.load(saved_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bbb3bd0-2c09-4078-83ed-0a9cfcb9032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageComparisonModel(\n",
       "  (stream1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (stream2): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (comparison): Sequential(\n",
       "    (0): Linear(in_features=131072, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f10836dc-1814-4842-bba2-1c0f988356a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "root_dir1 = 'data_test/chemdraw_LastTestSet'\n",
    "root_dir2 = 'data_test/chemdraw_LastTestSet_smlies'\n",
    "root_dir3 = 'data_test/chemdraw_LastTestSet_smlies_wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e38b86e3-4512-4d5a-88ae-f267e4376bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 내 모든 이미지 파일 경로 가져오기\n",
    "image_files1 = [os.path.join(root_dir1, filename) for filename in os.listdir(root_dir1) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "image_files2 = [os.path.join(root_dir2, filename) for filename in os.listdir(root_dir2) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "image_files3 = [os.path.join(root_dir3, filename) for filename in os.listdir(root_dir3) if filename.endswith(('.png', '.jpg', '.jpeg'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58528dd6-c123-4bea-b02f-43b42533f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일을 모두 불러와서 리스트에 저장\n",
    "images1 = [Image.open(img_path).convert(\"RGB\") for img_path in image_files1]\n",
    "images2 = [Image.open(img_path).convert(\"RGB\") for img_path in image_files2]\n",
    "images3 = [Image.open(img_path).convert(\"RGB\") for img_path in image_files3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192364fd-154a-4085-acbd-28d59383062d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageComparisonModel(\n",
       "  (stream1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (stream2): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (comparison): Sequential(\n",
       "    (0): Linear(in_features=131072, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 CUDA 장치로 이동\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "396e1294-3c6c-4dc0-92a1-671edffba508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████▉| 499/500 [00:02<00:00, 213.81image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 결과 저장을 위한 리스트\n",
    "results = []\n",
    "\n",
    "# 예측 레이블과 정답 레이블을 저장할 리스트\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "# 레이블 지정\n",
    "label = 1\n",
    "\n",
    "# tqdm을 사용하여 진행 상황 표시\n",
    "for img1_name, img1 in zip(image_files1, tqdm(images1, desc=\"Processing images\", unit=\"image\")):\n",
    "    # img1과 대응되는 이미지2를 찾음\n",
    "    img1_idx = image_files1.index(img1_name)  # img1의 인덱스\n",
    "    img2_name, img2 = image_files2[img1_idx], images2[img1_idx]  # 대응되는 img2의 이름과 이미지\n",
    "\n",
    "    # 이미지를 모델 입력에 맞게 전처리\n",
    "    img1_tensor = transform(img1).unsqueeze(0).to(device)  # GPU로 이동\n",
    "    img2_tensor = transform(img2).unsqueeze(0).to(device)  # GPU로 이동\n",
    "\n",
    "    # 이미지를 비교하여 예측 수행\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(img1_tensor, img2_tensor)\n",
    "        similarity = torch.sigmoid(output).item()\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append([img1_name, img2_name, similarity])\n",
    "    # 예측 레이블과 정답 레이블 저장\n",
    "    predicted_labels.append(1 if similarity > 0.5 else 0)\n",
    "    true_labels.append(label)  # 레이블은 1로 설정\n",
    "\n",
    "print(\"완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02835e61-3700-40e2-a2d1-0a7e368bde88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to image_similarity_results_wrong.csv\n"
     ]
    }
   ],
   "source": [
    "# 결과를 DataFrame으로 변환\n",
    "df = pd.DataFrame(results, columns=['image1_name', 'image2_name', 'similarity'])\n",
    "\n",
    "# 예측 레이블 및 정답 레이블 추가\n",
    "df['predicted_label'] = predicted_labels\n",
    "df['true_label'] = true_labels\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_csv_path = \"image_similarity_results_wrong.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7981316f-9b2e-4348-91dd-3fc99646753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0   0]\n",
      " [109 391]]\n"
     ]
    }
   ],
   "source": [
    "# 혼동 행렬 계산\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b7ef2e8-3241-46c6-b3ed-bbbf790f24ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.782\n",
      "F1 Score: 0.877665544332211\n"
     ]
    }
   ],
   "source": [
    "# 정밀도 계산\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b9159-662e-4e96-9ac4-b98a6631918f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
